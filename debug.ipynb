{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec, tensor_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "coord = np.array([[34, 51, 44, 61], [74, 64, 94, 74], [-5,  4,  5, 24]])\n",
    "\n",
    "im = Image.new(\"L\", (100, 100))\n",
    "draw = ImageDraw.Draw(im)\n",
    "\n",
    "for _, c in enumerate(coord):\n",
    "    draw.rectangle(tuple(c), fill=256)\n",
    "\n",
    "# normalize & transform image\n",
    "# x = np.array(im, dtype=np.float) / 255.0\n",
    "# x = np.expand_dims(x, axis=-1)  # (H, W, C=1)\n",
    "\n",
    "np.array(im).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/agents/mysrc\n",
      "[[117  41 127  51]\n",
      " [ 88 102 108 112]\n",
      " [ 45  96  55 116]]\n",
      "[[ 0  0 10 10]\n",
      " [ 0  0 20 10]\n",
      " [ 0  0 10 20]]\n",
      "[20  0]\n",
      "[[ 0  0 10 10]\n",
      " [ 0  0 20 10]\n",
      " [ 0  0 10 20]]\n",
      "[20  0]\n",
      "[[ 0  0 10 10]\n",
      " [20  0 40 10]\n",
      " [ 0  0 10 20]]\n",
      "[[ 0  0 10 10]\n",
      " [20  0 40 10]\n",
      " [ 0  0 10 20]]\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%cd /tf/agents/mysrc\n",
    "\n",
    "from PIL import Image\n",
    "from envs.toy import RectEnv, CANVAS_WIDTH\n",
    "\n",
    "env = RectEnv()\n",
    "env.reset()\n",
    "\n",
    "obs, r, _, _ = env.step((1, 1, 4))\n",
    "\n",
    "\n",
    "# x.shape\n",
    "# x = (obs['target'] * 256).astype(np.uint8).squeeze(axis=2)\n",
    "# x.shape\n",
    "\n",
    "# Image.fromarray(x, mode=\"L\")\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 37]\n",
      " [31 17]\n",
      " [13 90]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 75,  32,  85,  42],\n",
       "       [ 21,  12,  41,  22],\n",
       "       [  8,  80,  18, 100]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.clip(np.random.rand(2), 0.1, 0.3)\n",
    "# np.random.uniform(low=0.1, high=0.3, size=(2))\n",
    "width = 100\n",
    "rects_wh = np.array([[10, 10], [20, 10], [10, 20]], dtype=np.float) / width\n",
    "# np.array([np.concatenate([[0, 0], wh]) for wh in rects_wh])\n",
    "cxy = np.random.rand(3, 2)\n",
    "bbox = (np.concatenate([cxy-rects_wh/2, cxy+rects_wh/2], axis=1) * width).astype(np.int32)\n",
    "print((cxy * width).astype(np.int32))\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5., -5.,  5.,  5.],\n",
       "       [ 7.,  7., 17., 17.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items = 2\n",
    "# cxy = np.random.rand(n_items, 2)  # (N, 2)\n",
    "cxy = np.array([[0, 0], [12, 12]])\n",
    "wh = np.tile([10, 10], (2, 1))\n",
    "xy0 = cxy - wh/2\n",
    "xy1 = cxy + wh/2\n",
    "np.concatenate([xy0, xy1], axis=1)\n",
    "# np.concatenate([cxy, cxy + np.tile([10, 10], (2, 1))], axis=1)  # (N)\n",
    "# np.tile([10, 10], (2, 1))\n",
    "# np.array([[1,1],[2,2]]) + np.array([[3,3],[4,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "w = 128\n",
    "im = Image.new(\"L\", (w, w))\n",
    "draw = ImageDraw.Draw(im)\n",
    "\n",
    "coord = (coord * w).astype(np.int16)\n",
    "for _, c in enumerate(coord):\n",
    "    draw.rectangle(tuple(c), fill=255)\n",
    "\n",
    "# normalize & transform image\n",
    "x = np.array(im, dtype=np.float32) / 255.0\n",
    "x = np.expand_dims(x, axis=-1)  # (H, W, C=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/agents/mysrc\n",
      "7 1 13\n",
      "2020-01-10 18:56:51.898367: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-01-10 18:56:51.898555: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-01-10 18:56:51.898632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (63600c1a1877): /proc/driver/nvidia/version does not exist\n",
      "2020-01-10 18:56:51.899524: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-01-10 18:56:51.923386: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 1296000000 Hz\n",
      "2020-01-10 18:56:51.923705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5354130 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-01-10 18:56:51.923734: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "I0110 18:56:52.032344 139744173909824 parallel_py_environment.py:82] Spawning all processes.\n",
      "I0110 18:56:52.142622 139744173909824 parallel_py_environment.py:89] All processes started.\n",
      "I0110 18:56:52.978101 139744173909824 common.py:923] No checkpoint available at /tf/agents/log/ppo/gym/HalfCheetah-v2/train\n",
      "I0110 18:56:52.984025 139744173909824 common.py:923] No checkpoint available at /tf/agents/log/ppo/gym/HalfCheetah-v2/train/policy\n",
      "I0110 18:58:03.945898 139744173909824 ppo_example.py:292] step = 0, loss = 1834.413452\n",
      "I0110 18:58:03.946165 139744173909824 ppo_example.py:295] 0.000 steps/sec\n",
      "I0110 18:58:03.946795 139744173909824 ppo_example.py:297] collect_time = 1.4027788639068604, train_time = 64.97980189323425\n",
      "I0110 18:58:04.433305 139744173909824 common.py:941] Saved checkpoint: /tf/agents/log/ppo/gym/HalfCheetah-v2/train/ckpt-0\n",
      "I0110 18:58:04.651662 139744173909824 common.py:941] Saved checkpoint: /tf/agents/log/ppo/gym/HalfCheetah-v2/train/policy/ckpt-0\n",
      "2020-01-10 18:58:05.806222: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1788: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0110 18:58:06.567942 139744173909824 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1788: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tf/agents/log/ppo/gym/HalfCheetah-v2/policy_saved_model/policy_000000000/assets\n",
      "I0110 18:58:07.096303 139744173909824 builder_impl.py:775] Assets written to: /tf/agents/log/ppo/gym/HalfCheetah-v2/policy_saved_model/policy_000000000/assets\n",
      "I0110 18:58:24.930241 139744173909824 ppo_example.py:292] step = 50, loss = 1824.504639\n",
      "I0110 18:58:24.930555 139744173909824 ppo_example.py:295] 2.847 steps/sec\n",
      "I0110 18:58:24.930824 139744173909824 ppo_example.py:297] collect_time = 0.6807677745819092, train_time = 16.878566026687622\n",
      "I0110 18:58:42.535961 139744173909824 ppo_example.py:292] step = 100, loss = 1314.865723\n",
      "I0110 18:58:42.536263 139744173909824 ppo_example.py:295] 2.843 steps/sec\n",
      "I0110 18:58:42.536530 139744173909824 ppo_example.py:297] collect_time = 0.6956436634063721, train_time = 16.889464855194092\n",
      "I0110 18:59:00.337967 139744173909824 ppo_example.py:292] step = 150, loss = 549.931152\n",
      "I0110 18:59:00.338206 139744173909824 ppo_example.py:295] 2.813 steps/sec\n",
      "I0110 18:59:00.338324 139744173909824 ppo_example.py:297] collect_time = 0.7390327453613281, train_time = 17.035045862197876\n",
      "I0110 18:59:18.339940 139744173909824 ppo_example.py:292] step = 200, loss = 316.951538\n",
      "I0110 18:59:18.340220 139744173909824 ppo_example.py:295] 2.782 steps/sec\n",
      "I0110 18:59:18.340332 139744173909824 ppo_example.py:297] collect_time = 0.6842896938323975, train_time = 17.287835359573364\n",
      "I0110 18:59:36.984906 139744173909824 ppo_example.py:292] step = 250, loss = 235.245255\n",
      "I0110 18:59:36.985196 139744173909824 ppo_example.py:295] 2.685 steps/sec\n",
      "I0110 18:59:36.985436 139744173909824 ppo_example.py:297] collect_time = 0.7614772319793701, train_time = 17.85868263244629\n",
      "I0110 18:59:56.345461 139744173909824 ppo_example.py:292] step = 300, loss = 260.463806\n",
      "I0110 18:59:56.345752 139744173909824 ppo_example.py:295] 2.586 steps/sec\n",
      "I0110 18:59:56.345998 139744173909824 ppo_example.py:297] collect_time = 0.6833469867706299, train_time = 18.648088932037354\n",
      "I0110 19:00:16.398906 139744173909824 ppo_example.py:292] step = 350, loss = 180.725266\n",
      "I0110 19:00:16.399402 139744173909824 ppo_example.py:295] 2.497 steps/sec\n",
      "I0110 19:00:16.399615 139744173909824 ppo_example.py:297] collect_time = 0.8540782928466797, train_time = 19.17309331893921\n",
      "I0110 19:00:38.181166 139744173909824 ppo_example.py:292] step = 400, loss = 222.206894\n",
      "I0110 19:00:38.181385 139744173909824 ppo_example.py:295] 2.300 steps/sec\n",
      "I0110 19:00:38.181596 139744173909824 ppo_example.py:297] collect_time = 0.8417119979858398, train_time = 20.898484230041504\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%cd /tf/agents/mysrc\n",
    "!python ppo_example.py --root_dir=/tf/agents/log/ppo/gym/HalfCheetah-v2/ --num_parallel_environments=1 --collect_episodes_per_iteration=7 --num_eval_episodes=13 --logtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/agents/mysrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tf_agents.drivers.dynamic_episode_driver failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/tf/agents/tf_agents/drivers/dynamic_episode_driver.py\", line 46, in <module>\n",
      "    class DynamicEpisodeDriver(driver.Driver):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gin/config.py\", line 1129, in configurable\n",
      "    return perform_decoration(decoration_target)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gin/config.py\", line 1126, in perform_decoration\n",
      "    return _make_configurable(fn_or_cls, name, module, whitelist, blacklist)\n",
      "ValueError: A configurable matching 'tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver' already exists.\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)), observation=OrderedDict([('canvas', BoundedTensorSpec(shape=(64, 64, 1), dtype=tf.float32, name='observation/canvas', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))), ('coord', BoundedTensorSpec(shape=(2, 4), dtype=tf.float32, name='observation/coord', minimum=array(-10., dtype=float32), maximum=array(10., dtype=float32))), ('target', BoundedTensorSpec(shape=(64, 64, 1), dtype=tf.float32, name='observation/target', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))]))\n",
      "(BoundedTensorSpec(shape=(), dtype=tf.int64, name='action/tuple_0', minimum=array(0), maximum=array(1)), BoundedTensorSpec(shape=(), dtype=tf.int64, name='action/tuple_1', minimum=array(0), maximum=array(4)), BoundedTensorSpec(shape=(), dtype=tf.int64, name='action/tuple_2', minimum=array(0), maximum=array(4)))\n",
      "OrderedDict([('canvas', BoundedTensorSpec(shape=(64, 64, 1), dtype=tf.float32, name='observation/canvas', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))), ('coord', BoundedTensorSpec(shape=(2, 4), dtype=tf.float32, name='observation/coord', minimum=array(-10., dtype=float32), maximum=array(10., dtype=float32))), ('target', BoundedTensorSpec(shape=(64, 64, 1), dtype=tf.float32, name='observation/target', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))])\n",
      "Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=DictWrapper(OrderedDict([('canvas', BoundedTensorSpec(shape=(64, 64, 1), dtype=tf.float32, name='observation/canvas', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))), ('coord', BoundedTensorSpec(shape=(2, 4), dtype=tf.float32, name='observation/coord', minimum=array(-10., dtype=float32), maximum=array(10., dtype=float32))), ('target', BoundedTensorSpec(shape=(64, 64, 1), dtype=tf.float32, name='observation/target', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))])), action=(BoundedTensorSpec(shape=(), dtype=tf.int64, name='action/tuple_0', minimum=array(0), maximum=array(1)), BoundedTensorSpec(shape=(), dtype=tf.int64, name='action/tuple_1', minimum=array(0), maximum=array(4)), BoundedTensorSpec(shape=(), dtype=tf.int64, name='action/tuple_2', minimum=array(0), maximum=array(4))), policy_info=_TupleWrapper((DictWrapper({'logits': TensorSpec(shape=(2,), dtype=tf.float32, name='CategoricalProjectionNetwork_logits')}), DictWrapper({'logits': TensorSpec(shape=(5,), dtype=tf.float32, name='CategoricalProjectionNetwork_logits')}), DictWrapper({'logits': TensorSpec(shape=(5,), dtype=tf.float32, name='CategoricalProjectionNetwork_logits')}))), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " input must be 4-dimensional[2,1,64,64,1]\n\t [[{{node driver_loop/body/_1/ActorDistributionNetwork/EncodingNetwork/sequential_76/conv2d_54/BiasAdd}}]] [Op:__inference_run_917680]\n\nFunction call stack:\nrun\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-81fa48df9531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mppo_toy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/agents/mysrc/ppo_toy.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# for _ in range(10):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mcollect_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;31m# total_loss, _ = train_step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# replay_buffer.clear()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    636\u001b[0m               *args, **kwds)\n\u001b[1;32m    637\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1605\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1606\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1685\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1687\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1688\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1689\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    542\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  input must be 4-dimensional[2,1,64,64,1]\n\t [[{{node driver_loop/body/_1/ActorDistributionNetwork/EncodingNetwork/sequential_76/conv2d_54/BiasAdd}}]] [Op:__inference_run_917680]\n\nFunction call stack:\nrun\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%cd /tf/agents/mysrc\n",
    "from ppo_toy import train\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1357,), dtype=float32, numpy=\n",
       " array([ 0.09738518,  0.425965  , -0.06698334, ...,  0.19842806,\n",
       "         0.7509032 , -0.73973745], dtype=float32)>, ())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.networks import encoding_network\n",
    "\n",
    "observation_spec =  {\n",
    "    'image': tensor_spec.BoundedTensorSpec((16, 16, 3), np.float32, minimum=0, maximum=255),\n",
    "    'vector': tensor_spec.BoundedTensorSpec((5,), np.float32, minimum=-100, maximum=100)}\n",
    "preprocessing_layers = {\n",
    "    'image': tf.keras.models.Sequential([tf.keras.layers.Conv2D(8, 4),\n",
    "                                        tf.keras.layers.Flatten()]),\n",
    "    'vector': tf.keras.layers.Dense(5)}\n",
    "preprocessing_combiner = tf.keras.layers.Concatenate(axis=-1)\n",
    "\n",
    "\n",
    "encoder = encoding_network.EncodingNetwork(\n",
    "        input_tensor_spec=observation_spec,\n",
    "        preprocessing_layers=preprocessing_layers,\n",
    "        preprocessing_combiner=preprocessing_combiner,\n",
    "#         conv_layer_params=conv_layer_params,\n",
    "#         fc_layer_params=fc_layer_params,\n",
    "#         dropout_layer_params=dropout_layer_params,\n",
    "#         activation_fn=activation_fn,\n",
    "#         kernel_initializer=kernel_initializer,\n",
    "#         batch_squash=batch_squash,\n",
    "#         dtype=dtype\n",
    ")\n",
    "\n",
    "state, network_state = encoder({\n",
    "    \"image\":tf.random.uniform((16,16,3)),\n",
    "    \"vector\": tf.random.uniform((5,))\n",
    "})\n",
    "state, network_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
